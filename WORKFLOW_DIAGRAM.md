# ğŸ”„ MLOps Workflow Diagram

Complete end-to-end pipeline for Water Potability Prediction project

---

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DEVELOPER WORKFLOW                               â”‚
â”‚                                                                     â”‚
â”‚  1. Make Code Changes  â†’  2. Commit & Push  â†’  3. GitHub Actions  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GITHUB ACTIONS CI/CD PIPELINE                      â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€ Build Job â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â”œâ”€ Install Dependencies                                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ Run Tests (pytest)                                     â”‚   â”‚
â”‚  â”‚ â”œâ”€ Build Docker Image                                     â”‚   â”‚
â”‚  â”‚ â””â”€ Push to GitHub Container Registry (ghcr.io)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                          â”‚
â”‚                          â–¼                                          â”‚
â”‚  â”Œâ”€ Deploy Job â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â”œâ”€ SSH into EC2                                            â”‚  â”‚
â”‚  â”‚ â”œâ”€ Git Pull Latest Code                                    â”‚  â”‚
â”‚  â”‚ â”œâ”€ Docker Compose Down (stop old)                          â”‚  â”‚
â”‚  â”‚ â”œâ”€ Docker Compose Up (start new)                           â”‚  â”‚
â”‚  â”‚ â””â”€ Health Check                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               RUNNING ON AWS EC2 (PRODUCTION)                       â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Ubuntu EC2 Instance (46.137.144.250)                       â”‚  â”‚
â”‚  â”‚                                                              â”‚  â”‚
â”‚  â”‚  â”Œâ”€ Docker Container â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚                                                       â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  FastAPI Application (main.py)                       â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ REST API (localhost:8000)                        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ Web Dashboard (static files)                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€ Health Checks                                    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                       â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  Model Components:                                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ Trained Model (model.joblib)                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”œâ”€ Feature Scaler (scaler.joblib)                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€ Model Versions (v1, v2, v3, etc)                â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                       â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚  ğŸ“ Persistent Volumes:                                    â”‚  â”‚
â”‚  â”‚  â”œâ”€ /app/models/     (model files & versions)             â”‚  â”‚
â”‚  â”‚  â”œâ”€ /app/data/       (training data)                      â”‚  â”‚
â”‚  â”‚  â””â”€ /app/Data-set/   (original datasets)                  â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
         ğŸŒ USER ACCESS: http://46.137.144.250:8000
         âœ… Web UI for predictions
         âœ… API endpoints (/docs, /predict, /retrain)
         âœ… Model management (/versions, /switch-version)
```

---

## ğŸ” Complete Data & Model Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Training Data       â”‚
â”‚ train_dataset.csv (2,293 samples)
â”‚ test_dataset.csv  (1,000 samples)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: DATA PREPROCESSING                           â”‚
â”‚ (src/preprocess_presplit.py)                         â”‚
â”‚                                                      â”‚
â”‚ âœ“ Handle missing values                              â”‚
â”‚ âœ“ Feature scaling (StandardScaler)                   â”‚
â”‚ âœ“ Remove outliers                                    â”‚
â”‚ âœ“ Split train/test                                   â”‚
â”‚                                                      â”‚
â”‚ Controlled by: params.yaml (preprocess section)      â”‚
â”‚ Output: data/train.csv, data/test.csv                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: MODEL TRAINING                               â”‚
â”‚ (src/train_ensemble.py)                              â”‚
â”‚                                                      â”‚
â”‚ Trains 3 ensemble models:                            â”‚
â”‚ 1ï¸âƒ£  Random Forest (250 trees)                       â”‚
â”‚ 2ï¸âƒ£  XGBoost (300 boosted trees)                     â”‚
â”‚ 3ï¸âƒ£  Gradient Boosting (250 trees)                   â”‚
â”‚                                                      â”‚
â”‚ Combines via VotingClassifier (soft voting)          â”‚
â”‚ Controlled by: params.yaml (train section)           â”‚
â”‚ Output: models/model.joblib                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: MODEL EVALUATION                             â”‚
â”‚ (src/evaluate.py)                                    â”‚
â”‚                                                      â”‚
â”‚ Calculate metrics:                                   â”‚
â”‚ â€¢ Accuracy: 84.39%                                   â”‚
â”‚ â€¢ Precision: 82.40%                                  â”‚
â”‚ â€¢ Recall: 83.29%                                     â”‚
â”‚ â€¢ F1-Score: 82.84%                                   â”‚
â”‚ â€¢ Cross-Val Score: 64.24%                            â”‚
â”‚                                                      â”‚
â”‚ Output: metrics.json                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DVC ORCHESTRATION                                    â”‚
â”‚ (dvc.yaml - ties everything together)                â”‚
â”‚                                                      â”‚
â”‚ dvc repro runs:                                      â”‚
â”‚ 1. preprocess stage                                  â”‚
â”‚ 2. train stage                                       â”‚
â”‚ 3. evaluate stage                                    â”‚
â”‚                                                      â”‚
â”‚ Tracks data versions & reproducibility               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ³ Docker & Deployment Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dockerfile (Multi-stage build)    â”‚
â”‚                                    â”‚
â”‚  Stage 1: Base (Python 3.12.2)     â”‚
â”‚  â”œâ”€ System dependencies            â”‚
â”‚  â””â”€ Environment setup              â”‚
â”‚                                    â”‚
â”‚  Stage 2: Dependencies             â”‚
â”‚  â”œâ”€ pip install -r requirements.txt
â”‚  â””â”€ Install DVC, scikit-learn, etc â”‚
â”‚                                    â”‚
â”‚  Stage 3: Application              â”‚
â”‚  â”œâ”€ Copy project files             â”‚
â”‚  â”œâ”€ Create directories             â”‚
â”‚  â”œâ”€ Health checks                  â”‚
â”‚  â””â”€ CMD: uvicorn main:app          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Docker Image Built â”‚
        â”‚ ~500 MB optimized  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ GitHub Container Registry    â”‚
    â”‚ ghcr.io/tejasthange3/        â”‚
    â”‚ mlops-water-potability:latestâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  docker-compose.yml                â”‚
â”‚                                    â”‚
â”‚  Services:                         â”‚
â”‚  â”œâ”€ mlops-api                      â”‚
â”‚  â”‚  â”œâ”€ Image: ghcr.io/...latest  â”‚
â”‚  â”‚  â”œâ”€ Port: 8000                 â”‚
â”‚  â”‚  â”œâ”€ Volumes: (models, data)    â”‚
â”‚  â”‚  â””â”€ Restart policy             â”‚
â”‚  â”‚                                â”‚
â”‚  â””â”€ Health check every 30 sec      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EC2 Instance Runs Container       â”‚
â”‚                                    â”‚
â”‚  Commands:                         â”‚
â”‚  $ docker-compose down             â”‚
â”‚  $ docker-compose up -d            â”‚
â”‚                                    â”‚
â”‚  Result:                           â”‚
â”‚  âœ… Container running              â”‚
â”‚  âœ… Port 8000 listening            â”‚
â”‚  âœ… API accepting requests         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ CI/CD Automation Workflows

### **Workflow 1: Deploy on Push (deploy.yml)**

```
EVENT: Push to main branch
  â”‚
  â–¼
â”œâ”€ Checkout Code
â”œâ”€ Setup Python 3.12
â”œâ”€ Install Dependencies
â”œâ”€ Run Tests (pytest)
â”œâ”€ Build Docker Image
â”‚   â”œâ”€ Tag: ghcr.io/.../mlops-water-potability:$COMMIT_SHA
â”‚   â””â”€ Tag: ghcr.io/.../mlops-water-potability:latest
â”œâ”€ Login to GitHub Container Registry
â”œâ”€ Push Docker Image
â”‚   â”œâ”€ Push :$COMMIT_SHA tag
â”‚   â””â”€ Push :latest tag
â”‚
â””â”€ Deploy to EC2 (SSH)
    â”œâ”€ Clone/Pull Repository
    â”œâ”€ docker compose down
    â”œâ”€ docker compose up -d
    â”œâ”€ Wait 5 seconds
    â”œâ”€ curl http://localhost:8000/health
    â””â”€ âœ… Deployment Complete

RESULT: Application live in 2-3 minutes
```

### **Workflow 2: ML Training Pipeline (mlops-pipeline.yml)**

```
EVENT: Daily at 2 AM UTC (or manual trigger)
  â”‚
  â–¼
Job 1: Data Validation
â”œâ”€ Load datasets
â”œâ”€ Check structure
â”œâ”€ Verify non-empty
â””â”€ âœ… Data validated

  â”‚
  â–¼
Job 2: Model Training
â”œâ”€ Run: dvc repro
â”‚   â”œâ”€ Preprocess data
â”‚   â”œâ”€ Train ensemble model
â”‚   â””â”€ Evaluate performance
â”œâ”€ Generate metrics.json
â””â”€ âœ… Model trained

  â”‚
  â–¼
Job 3: Unit Tests
â”œâ”€ pytest -v --cov=src
â”œâ”€ Test all functions
â”œâ”€ Generate coverage report
â””â”€ âœ… Tests passed

  â”‚
  â–¼
Job 4: API Integration Tests
â”œâ”€ Start uvicorn server
â”œâ”€ Test /health endpoint
â”œâ”€ Test /predict endpoint
â”œâ”€ Verify responses
â””â”€ âœ… API working

  â”‚
  â–¼
Upload Artifacts
â”œâ”€ metrics.json
â”œâ”€ coverage report
â””â”€ âœ… Artifacts stored
```

---

## ğŸŒ User Interaction Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER INTERACTION                   â”‚
â”‚  http://46.137.144.250:8000         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚
        â–¼               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Web UI   â”‚   â”‚ API Endpoint â”‚
   â”‚ (HTML)   â”‚   â”‚ (/predict)   â”‚
   â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚
      â”‚    Input Parameters:
      â”‚    â€¢ pH, Hardness, Solids
      â”‚    â€¢ Chloramines, Sulfate
      â”‚    â€¢ Conductivity
      â”‚    â€¢ Organic_carbon
      â”‚    â€¢ Trihalomethanes
      â”‚    â€¢ Turbidity
      â”‚
      â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FastAPI Server        â”‚
    â”‚  (main.py)             â”‚
    â”‚                        â”‚
    â”‚  1. Validate input     â”‚
    â”‚  2. Scale features     â”‚
    â”‚  3. Load model         â”‚
    â”‚  4. Make prediction    â”‚
    â”‚  5. Return result      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  RESPONSE              â”‚
    â”‚  {                     â”‚
    â”‚    "potability": 1,    â”‚
    â”‚    "label": "Potable", â”‚
    â”‚    "confidence": 0.85  â”‚
    â”‚  }                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
        â–¼         â–¼
    Display   Return JSON
    on UI     to API caller
```

---

## ğŸ” Model Retraining Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER PROVIDES FEEDBACK              â”‚
â”‚ "This prediction was wrong!"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Collect Feedback        â”‚
    â”‚ â€¢ Prediction made       â”‚
    â”‚ â€¢ Actual label (0 or 1) â”‚
    â”‚ â€¢ Timestamp             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Retrain Endpoint (/retrain)         â”‚
    â”‚                                     â”‚
    â”‚ 1. Add to incremental_training_     â”‚
    â”‚    data.csv                         â”‚
    â”‚ 2. Load original training data      â”‚
    â”‚ 3. Combine datasets                 â”‚
    â”‚ 4. Retrain ensemble model           â”‚
    â”‚ 5. Evaluate new model               â”‚
    â”‚ 6. Save as new version (V1, V2...)  â”‚
    â”‚ 7. Update metadata.json             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ NEW MODEL VERSION        â”‚
    â”‚                          â”‚
    â”‚ models/versions/         â”‚
    â”‚ â”œâ”€ model_V1.joblib       â”‚
    â”‚ â”œâ”€ model_V2.joblib (NEW) â”‚
    â”‚ â”œâ”€ scaler_V1.joblib      â”‚
    â”‚ â”œâ”€ scaler_V2.joblib (NEW)â”‚
    â”‚ â””â”€ metadata.json (updated)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ USER CAN NOW:            â”‚
    â”‚                          â”‚
    â”‚ â€¢ Use new model (V2)     â”‚
    â”‚ â€¢ Switch back to V1      â”‚
    â”‚ â€¢ View metrics for each  â”‚
    â”‚ â€¢ Compare versions       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ File Dependencies

```
Data Flow:
Data-set/train_dataset.csv
           â†“
    [preprocess_presplit.py] â† params.yaml (preprocess)
           â†“
      data/train.csv
           â†“
    [train_ensemble.py] â† params.yaml (train)
           â†“
    models/model.joblib
           â†“
    [evaluate.py] â† models/model.joblib
           â†“
    metrics.json
           â†“
    [GitHub Actions] â† stores as artifact

Application Flow:
models/model.joblib
models/scaler.joblib  â”€â”€â†’ [main.py] â†’ FastAPI Server
static/index.html        â†‘
src/model_manager.py â”€â”€â”€â”€â”€â”˜

Deployment:
.github/workflows/deploy.yml
        â†“
    [GitHub Actions]
        â”œâ”€ Build Docker Image (Dockerfile)
        â”œâ”€ Push to ghcr.io
        â””â”€ Deploy to EC2 (docker-compose.yml)

CI/CD Pipelines:
.github/workflows/mlops-pipeline.yml (daily training)
.github/workflows/deploy.yml (on push to main)
```

---

## ğŸ¯ Key Touchpoints

| Phase          | Technology              | Input        | Output          | Time    |
| -------------- | ----------------------- | ------------ | --------------- | ------- |
| **Preprocess** | Python + scikit-learn   | Raw CSV      | Scaled CSV      | ~2 sec  |
| **Train**      | XGBoost + Random Forest | Scaled CSV   | Model.joblib    | ~30 sec |
| **Evaluate**   | scikit-learn metrics    | Model + Data | metrics.json    | ~5 sec  |
| **Package**    | Docker                  | Code + Model | Container Image | ~2 min  |
| **Deploy**     | GitHub Actions + SSH    | Docker Image | EC2 Running     | ~3 min  |
| **Predict**    | FastAPI                 | JSON params  | JSON result     | ~100 ms |
| **Retrain**    | Model Manager           | Feedback     | New Version     | ~30 sec |

---

## âš¡ Quick Command Reference

```bash
# LOCAL DEVELOPMENT
dvc repro                          # Run full pipeline
python main.py                     # Run locally
pytest -v                          # Run tests

# DOCKER
docker build -t mlops .            # Build image
docker-compose up -d               # Start containers
docker-compose logs -f             # View logs
docker-compose down                # Stop containers

# GIT & DEPLOYMENT
git push origin main               # Trigger CI/CD
# GitHub Actions automatically builds and deploys!

# EC2 MANUAL DEPLOYMENT
ssh -i mlops-project-key.pem ubuntu@<EC2_IP>
cd Mlops-Project
git pull origin main
docker-compose down
docker-compose up -d
curl http://localhost:8000/health # Verify
```

---

**Complete MLOps Workflow: From Data â†’ Model â†’ Container â†’ Cloud â˜ï¸**
